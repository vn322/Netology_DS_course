{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Задание\n",
        "* Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
        "* Обучите на них seq2seq по аналогии с занятием. Оцените полученное качество\n",
        "* Попробуйте добавить +1 рекуррентный слой в encoder и decoder\n",
        "* Попробуйте заменить GRU ячейки на lstm-ячейки"
      ],
      "metadata": {
        "id": "ZoeTKeKL6Ebr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFfkS6pRjHOR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHtAeHLLjJYd",
        "outputId": "2dc7ee5e-21f8-42b8-829e-96cda971d5a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-14 11:12:20--  https://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15460248 (15M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.74M  51.4MB/s    in 0.3s    \n",
            "\n",
            "2023-06-14 11:12:21 (51.4 MB/s) - ‘rus-eng.zip’ saved [15460248/15460248]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail rus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yfRzsUjKyC",
        "outputId": "b4a0ffbc-4a82-4849-d8d6-acd18098529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\tНам нужно отстаивать законы против дискриминации при найме на работу, в жилищной сфере, в сфере образования и правоохранительной системе. Этого требуют наша Конституция и высшие идеалы.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (BHO) & #6390439 (odexed)\n",
            "I've heard that you should never date anyone who is less than half your age plus seven. Tom is now 30 years old and Mary is 17. How many years will Tom need to wait until he can start dating Mary?\tЯ слышал, что никогда не следует встречаться с кем-то вдвое младше вас плюс семь лет. Тому 30 лет, a Мэри 17. Сколько лет Тому нужно ждать до тех пор, пока он сможет начать встречаться с Мэри?\tCC-BY 2.0 (France) Attribution: tatoeba.org #10068197 (CK) & #10644473 (notenoughsun)\n",
            "I do have one final ask of you as your president, the same thing I asked when you took a chance on me eight years ago. I'm asking you to believe, not in my ability to bring about change but in yours.\tУ меня же, как у вашего президента, есть к вам последняя просьба. Та же самая, что и восемь лет назад, когда вы оказали мне своё доверие. Я прошу вас верить, но не в мои способности добиться перемен, а в ваши.\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762723 (BHO) & #6390123 (odexed)\n",
            "In today's world, we have to equip all our kids with an education that prepares them for success, regardless of what they look like, or how much their parents make, or the zip code that they live in.\tВ современном мире перед нами стоит задача дать всем нашим детям такое образование, которое настроит их на успех вне зависимости от того, как они выглядят, сколько зарабатывают их родители или какой у них почтовый индекс.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924477 (BHO) & #5968115 (odexed)\n",
            "Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\tСмерть - это зачастую то, разговоры или даже мысли о чем приводят в уныние, но я осознал, что готовность умереть наделяет силой, как ничто другое. Мысль о смерти вносит ясность в твою жизнь.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #3231553 (kukla)\n",
            "At a moment when our economy is growing, our businesses are creating jobs at the fastest pace since the 1990s, and wages are starting to rise again, we have to make some choices about the kind of country we want to be.\tВ тот момент, когда наша экономика растёт, наши предприятия создают рабочие места наибольшими темпами, начиная с 90-х годов, а зарплаты снова начинают расти, мы должны принять ряд решений относительно того, какой страной мы хотим быть.\tCC-BY 2.0 (France) Attribution: tatoeba.org #3924474 (BHO) & #4509418 (odexed)\n",
            "When I was younger, I hated going to weddings. My grandmothers and aunts would huddle around me, poke me in the side, and giggle \"You're next! You're next!\" They only stopped this nonsense when I began to do the same thing at funerals.\tКогда я была помоложе, я ненавидела ходить на свадьбы. Мои бабушки и тётки толпились вокруг, тыкали меня в бок и говорили, посмеиваясь: «Ты следующая! Ты следующая!». Они перестали нести этот вздор только тогда, когда я начала делать то же самое на похоронах.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2776770 (AlanF_US) & #4311406 (odexed)\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
            "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
            "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "MtxSF1HljMcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+а-яА-Я\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "XMBj-QRDjQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('rus.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    for p in pairs:\n",
        "        p.pop()\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "\n",
        "    else:\n",
        "\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "tljl5hVfjR7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s\",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "yOLjuxPMjTXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vi_9rdzjU6a",
        "outputId": "c83c7b3b-1c6b-4057-edcd-7328d075d0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 467119 sentence pairs\n",
            "Trimmed to 4269 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "rus 3913\n",
            "eng 2071\n",
            "['он менее терпелив, чем его брат .', 'he is less patient than his brother .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Encoder\n",
        "-----------"
      ],
      "metadata": {
        "id": "b-0Pt5oZjZUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "7Cn_FUFKjdTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decoder\n",
        "-----------\n"
      ],
      "metadata": {
        "id": "vt7mU-JvjeUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "qg__g07Tjf5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "wyThYIDtjimi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "MDP9ut87jkCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "TJyKxGLYjl4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "Oa0AOmoejnRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "fjPg_UZAjowK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "FtnGAKyfjqRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "SdsN7Hyxjr0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUFXA6AWjtKC",
        "outputId": "f6d55e89-15d7-4158-c05a-b7bdcc42f2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 31s (- 21m 25s) (5000 6%) 3.0835\n",
            "3m 5s (- 20m 4s) (10000 13%) 2.4664\n",
            "4m 40s (- 18m 41s) (15000 20%) 1.9849\n",
            "6m 15s (- 17m 13s) (20000 26%) 1.5713\n",
            "7m 50s (- 15m 40s) (25000 33%) 1.2122\n",
            "9m 24s (- 14m 6s) (30000 40%) 0.9321\n",
            "10m 58s (- 12m 32s) (35000 46%) 0.6690\n",
            "12m 32s (- 10m 58s) (40000 53%) 0.5174\n",
            "14m 8s (- 9m 25s) (45000 60%) 0.3800\n",
            "15m 43s (- 7m 51s) (50000 66%) 0.2834\n",
            "17m 17s (- 6m 17s) (55000 73%) 0.1848\n",
            "18m 52s (- 4m 43s) (60000 80%) 0.1363\n",
            "20m 27s (- 3m 8s) (65000 86%) 0.1109\n",
            "22m 2s (- 1m 34s) (70000 93%) 0.0819\n",
            "23m 36s (- 0m 0s) (75000 100%) 0.0582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, decoder1, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtlMUOYNjuZq",
        "outputId": "15cc22f6-bd43-4716-86af-a61657f629ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> у него аллергия на пыль .\n",
            "= he is allergic to dust .\n",
            "< he is allergic to dust . <EOS>\n",
            "\n",
            "> она моя одноклассница .\n",
            "= she is my classmate .\n",
            "< she is my classmate . <EOS>\n",
            "\n",
            "> я разведен .\n",
            "= i am divorced .\n",
            "< i am divorced . <EOS>\n",
            "\n",
            "> я боюсь смерти .\n",
            "= i am afraid of dying .\n",
            "< i am afraid of death . <EOS>\n",
            "\n",
            "> он, что называется, человек, которыи сделал себя сам .\n",
            "= he is what is called a self-made man .\n",
            "< he is what we call a self-made man . <EOS>\n",
            "\n",
            "> я боюсь собак .\n",
            "= i am afraid of dogs .\n",
            "< i am afraid of dogs . <EOS>\n",
            "\n",
            "> она говорит по-португальски .\n",
            "= she speaks portuguese .\n",
            "< she speaks portuguese . <EOS>\n",
            "\n",
            "> мне стыдно .\n",
            "= i am ashamed .\n",
            "< i am ashamed . <EOS>\n",
            "\n",
            "> она мне не подходит .\n",
            "= she is no match for me .\n",
            "< she is no match for me . <EOS>\n",
            "\n",
            "> его часто не бывает в школе .\n",
            "= he is often absent from school .\n",
            "< he is often absent from school . <EOS>\n",
            "\n",
            "> он занят подготовкои к поездке .\n",
            "= he is busy preparing for the trip .\n",
            "< he is busy preparing for the trip . <EOS>\n",
            "\n",
            "> он мои брат .\n",
            "= he is my brother .\n",
            "< he is my brother . <EOS>\n",
            "\n",
            "> он официант и актер .\n",
            "= he is a waiter and an actor .\n",
            "< he is a waiter and an actor . <EOS>\n",
            "\n",
            "> она стояла на голове .\n",
            "= she stood on her head .\n",
            "< she stood on her head . <EOS>\n",
            "\n",
            "> они работают в эти выходные .\n",
            "= they are working this weekend .\n",
            "< they are working this weekend . <EOS>\n",
            "\n",
            "> вам не разрешается купаться на этом пляже .\n",
            "= you aren't allowed to swim at this beach .\n",
            "< you aren't allowed to swim at this beach . <EOS>\n",
            "\n",
            "> они мои не настоящие родители .\n",
            "= they aren't my real parents .\n",
            "< they aren't my real parents . <EOS>\n",
            "\n",
            "> он плохо водит машину .\n",
            "= he is bad at driving .\n",
            "< he is bad at driving . <EOS>\n",
            "\n",
            "> она со мнои примерно одного возраста .\n",
            "= she is about my age .\n",
            "< she is about my age . <EOS>\n",
            "\n",
            "> мне будет вас не хватать .\n",
            "= i am going to miss you .\n",
            "< i am going to miss you . <EOS>\n",
            "\n",
            "> он болен .\n",
            "= he is ill .\n",
            "< he is ill . <EOS>\n",
            "\n",
            "> он всегда жалуется на свою низкую зарплату .\n",
            "= he is always complaining about his low salary .\n",
            "< he is always complaining about his low salary . <EOS>\n",
            "\n",
            "> он плохои человек .\n",
            "= he is a bad person .\n",
            "< he is a bad person . <EOS>\n",
            "\n",
            "> она покачала головои .\n",
            "= she shook her head .\n",
            "< she shook her head . <EOS>\n",
            "\n",
            "> он кто угодно, но не джентльмен .\n",
            "= he is anything but a gentleman .\n",
            "< he is anything but a gentleman . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим в encoder и decoder возможность добавлять рекурретный слой и менять rnn GRU/LSTM"
      ],
      "metadata": {
        "id": "HZ7XM7Qs7GhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_rnn = 1, rnnClass = \"GRU\"):\n",
        "        super(EncoderRNN1, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_rnn = num_rnn\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        if rnnClass == \"GRU\":\n",
        "          self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        elif rnnClass == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "        if self.num_rnn == 2:\n",
        "          if rnnClass == \"GRU\":\n",
        "              self.rnn_2 = nn.GRU(hidden_size, hidden_size)\n",
        "          elif rnnClass == \"LSTM\":\n",
        "              self.rnn_2 = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        if self.num_rnn == 2:\n",
        "          output, hidden = self.rnn_2(output, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "      if isinstance(self.rnn, nn.LSTM):\n",
        "          return (torch.zeros(1, 1, self.hidden_size, device=device), torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "      return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "iVj8aaQ3qVMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN1(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_rnn = 1, rnnClass = \"GRU\"):\n",
        "        super(DecoderRNN1, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_rnn = num_rnn\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        if rnnClass == \"GRU\":\n",
        "          self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        elif rnnClass == \"LSTM\":\n",
        "          self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "        if self.num_rnn == 2:\n",
        "           if rnnClass == \"GRU\":\n",
        "               self.rnn_2 = nn.GRU(hidden_size, hidden_size)\n",
        "           elif rnnClass == \"LSTM\":\n",
        "               self.rnn_2 = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        if self.num_rnn == 2:\n",
        "          output, hidden = self.rnn_2(output, hidden)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        if isinstance(self.rnn, nn.LSTM):\n",
        "            return (torch.zeros(1, 1, self.hidden_size, device=device),torch.zeros(1, 1, self.hidden_size, device=device))\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "dn1DcRM4q8fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#GRU +1 рекуррентный слой в encoder и decoder"
      ],
      "metadata": {
        "id": "DBc21p-m7ZE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder2 = EncoderRNN1(input_lang.n_words, hidden_size, num_rnn=2).to(device)\n",
        "decoder2 = DecoderRNN1(hidden_size, output_lang.n_words, num_rnn=2).to(device)\n",
        "\n",
        "trainIters(encoder2, decoder2, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN5GxxgvzccZ",
        "outputId": "9fee98ed-6fa6-4db0-f7cf-d286b35e96af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 18s (- 32m 20s) (5000 6%) 3.3312\n",
            "4m 36s (- 29m 57s) (10000 13%) 2.8534\n",
            "6m 54s (- 27m 38s) (15000 20%) 2.6345\n",
            "9m 17s (- 25m 32s) (20000 26%) 2.4974\n",
            "11m 38s (- 23m 16s) (25000 33%) 2.2613\n",
            "14m 2s (- 21m 4s) (30000 40%) 2.0063\n",
            "16m 25s (- 18m 45s) (35000 46%) 1.8461\n",
            "18m 46s (- 16m 25s) (40000 53%) 1.5996\n",
            "21m 9s (- 14m 6s) (45000 60%) 1.4149\n",
            "23m 34s (- 11m 47s) (50000 66%) 1.1855\n",
            "26m 3s (- 9m 28s) (55000 73%) 0.9919\n",
            "28m 30s (- 7m 7s) (60000 80%) 0.8329\n",
            "30m 57s (- 4m 45s) (65000 86%) 0.6436\n",
            "33m 21s (- 2m 22s) (70000 93%) 0.4969\n",
            "35m 49s (- 0m 0s) (75000 100%) 0.4132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder2, decoder2, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qqC1bJTzcyq",
        "outputId": "66ee6f34-75fb-43ff-8236-981f288e4721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> они обессилены .\n",
            "= they are exhausted .\n",
            "< they are exhausted . <EOS>\n",
            "\n",
            "> они неразлучны .\n",
            "= they are inseparable .\n",
            "< they are approaching . <EOS>\n",
            "\n",
            "> мы с тобои примерно ровесники .\n",
            "= you are about my age .\n",
            "< you are about my age . <EOS>\n",
            "\n",
            "> он студент университета .\n",
            "= he is a university student .\n",
            "< he is a university student . <EOS>\n",
            "\n",
            "> он хитрая лиса .\n",
            "= he is a sly fox .\n",
            "< he is a sly fox . <EOS>\n",
            "\n",
            "> он слишком осторожен, чтобы попробовать что-либо новое .\n",
            "= he is too cautious to try anything new .\n",
            "< he is too cautious to try anything new . <EOS>\n",
            "\n",
            "> она переплыла реку .\n",
            "= she swam across the river .\n",
            "< she swam across the river . <EOS>\n",
            "\n",
            "> мы извиняемся за неудобства .\n",
            "= we are sorry for the inconvenience .\n",
            "< we are going for peace . <EOS>\n",
            "\n",
            "> мы сотрудничаем со многими странами .\n",
            "= we are doing business with many countries .\n",
            "< we are doing with many with their . . <EOS>\n",
            "\n",
            "> он играет в своеи комнате .\n",
            "= he is playing in his room .\n",
            "< he is playing in his room . <EOS>\n",
            "\n",
            "> я так измучена !\n",
            "= i am so exhausted !\n",
            "< i am so exhausted ! <EOS>\n",
            "\n",
            "> ты пьян !\n",
            "= you are drunk !\n",
            "< you are drunk ! <EOS>\n",
            "\n",
            "> очень маловероятно, что мы будем путешествовать вместе .\n",
            "= we aren't very likely to travel together .\n",
            "< we aren't very likely to travel together . <EOS>\n",
            "\n",
            "> он занят написанием отчетов .\n",
            "= he is busy typing the reports .\n",
            "< he is busy typing the reports . <EOS>\n",
            "\n",
            "> я сеичас на дежурстве .\n",
            "= i am on duty now .\n",
            "< i am on duty now . <EOS>\n",
            "\n",
            "> он поправляется .\n",
            "= he is getting better .\n",
            "< he is getting better . <EOS>\n",
            "\n",
            "> он очень привязан к неи .\n",
            "= he is deeply attached to her .\n",
            "< he is deeply attached to her . <EOS>\n",
            "\n",
            "> она агрессивна .\n",
            "= she is aggressive .\n",
            "< she is aggressive . <EOS>\n",
            "\n",
            "> он спит .\n",
            "= he is asleep .\n",
            "< he is asleep . <EOS>\n",
            "\n",
            "> мы уезжаем из японии в следующем месяце .\n",
            "= we are leaving japan next month .\n",
            "< we are leaving japan next month . <EOS>\n",
            "\n",
            "> он, вероятно, придет .\n",
            "= he is likely to come .\n",
            "< he is likely to come . <EOS>\n",
            "\n",
            "> он очень ко мне добр .\n",
            "= he is very kind to me .\n",
            "< he is very kind . <EOS>\n",
            "\n",
            "> она бедствует .\n",
            "= she is badly off .\n",
            "< she is kissing . <EOS>\n",
            "\n",
            "> у него один глаз не видит .\n",
            "= he is blind in one eye .\n",
            "< he is blind in a bad . <EOS>\n",
            "\n",
            "> я ваша, а вы мои .\n",
            "= i am yours and you are mine .\n",
            "< i am yours and you are mine . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#LSTM"
      ],
      "metadata": {
        "id": "K5o0QEN97c33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder3 = EncoderRNN1(input_lang.n_words, hidden_size, rnnClass = \"LSTM\").to(device)\n",
        "decoder3 = DecoderRNN1(hidden_size, output_lang.n_words, rnnClass = \"LSTM\").to(device)\n",
        "\n",
        "trainIters(encoder3, decoder3, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj3rBiJRzdGB",
        "outputId": "41f27c84-50a7-48dc-bb78-4e72e6cd33c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 11s (- 30m 35s) (5000 6%) 3.2284\n",
            "4m 25s (- 28m 46s) (10000 13%) 2.7010\n",
            "6m 40s (- 26m 43s) (15000 20%) 2.3382\n",
            "8m 57s (- 24m 39s) (20000 26%) 1.9521\n",
            "11m 12s (- 22m 25s) (25000 33%) 1.6087\n",
            "13m 29s (- 20m 14s) (30000 40%) 1.3167\n",
            "15m 45s (- 18m 0s) (35000 46%) 1.0836\n",
            "18m 2s (- 15m 47s) (40000 53%) 0.8374\n",
            "20m 19s (- 13m 33s) (45000 60%) 0.6652\n",
            "22m 34s (- 11m 17s) (50000 66%) 0.5212\n",
            "24m 50s (- 9m 1s) (55000 73%) 0.3755\n",
            "27m 7s (- 6m 46s) (60000 80%) 0.2835\n",
            "29m 24s (- 4m 31s) (65000 86%) 0.2056\n",
            "31m 41s (- 2m 15s) (70000 93%) 0.1698\n",
            "33m 58s (- 0m 0s) (75000 100%) 0.1181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder3, decoder3, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXjhOaFX1M9x",
        "outputId": "3f93b5cd-3951-4641-b043-b31c9e1a5ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я ему не подхожу .\n",
            "= i am no match for him .\n",
            "< i am no match for him . <EOS>\n",
            "\n",
            "> мы очень рады вас видеть .\n",
            "= we are happy to see you .\n",
            "< we are happy to see you . <EOS>\n",
            "\n",
            "> еи рано идти в школу .\n",
            "= she is too young to go to school .\n",
            "< she is too young to go to school . <EOS>\n",
            "\n",
            "> он или пьян, или безумен .\n",
            "= he is either drunk or mad .\n",
            "< he is either drunk or mad . <EOS>\n",
            "\n",
            "> он очень осторожныи водитель .\n",
            "= he is a very careful driver .\n",
            "< he is a very careful driver . <EOS>\n",
            "\n",
            "> я из токио .\n",
            "= i am from tokyo .\n",
            "< i am from tokyo . <EOS>\n",
            "\n",
            "> у него редко хорошее настроение .\n",
            "= he is rarely in a good mood .\n",
            "< he is rarely in a good mood . <EOS>\n",
            "\n",
            "> я первыи музыкант в нашеи семье .\n",
            "= i am the first musician in my family .\n",
            "< i am the first musician in my family . <EOS>\n",
            "\n",
            "> он откладывает деньги на поездку за границу .\n",
            "= he is saving money for a trip abroad .\n",
            "< he is saving money for a trip abroad . <EOS>\n",
            "\n",
            "> я боюсь смерти .\n",
            "= i am afraid of dying .\n",
            "< i am afraid of death . <EOS>\n",
            "\n",
            "> он вовсе не счастлив .\n",
            "= he isn't happy at all .\n",
            "< he isn't happy at all . <EOS>\n",
            "\n",
            "> он сидит на стуле .\n",
            "= he is sitting on the chair .\n",
            "< he is sitting on the chair . <EOS>\n",
            "\n",
            "> он сидит развалившись на диване .\n",
            "= he is sprawled out on the sofa .\n",
            "< he is sprawled out on the sofa . <EOS>\n",
            "\n",
            "> она привыкла вставать рано .\n",
            "= she is used to getting up early .\n",
            "< she is used to getting up early . <EOS>\n",
            "\n",
            "> она не боится умереть .\n",
            "= she is not afraid to die .\n",
            "< she is not afraid to die . <EOS>\n",
            "\n",
            "> он англичанин .\n",
            "= he is english .\n",
            "< he is english . <EOS>\n",
            "\n",
            "> ты ведь не спешишь ?\n",
            "= you aren't in a hurry, are you ?\n",
            "< you aren't in a hurry, are you ? <EOS>\n",
            "\n",
            "> она на три года старше меня .\n",
            "= she is three years older than i am .\n",
            "< she is three years older than i am . <EOS>\n",
            "\n",
            "> она тихая женщина .\n",
            "= she is a quiet woman .\n",
            "< she is a quiet woman . <EOS>\n",
            "\n",
            "> очень рад снова вас видеть .\n",
            "= i am happy to see you again .\n",
            "< i am happy to see you again . <EOS>\n",
            "\n",
            "> ты мне не подруга .\n",
            "= you aren't my friend .\n",
            "< you aren't my friend . <EOS>\n",
            "\n",
            "> они готовятся к контрольнои .\n",
            "= they are studying for the test .\n",
            "< they are studying for the test . <EOS>\n",
            "\n",
            "> ты очень богата .\n",
            "= you are very rich .\n",
            "< you are very rich . <EOS>\n",
            "\n",
            "> он кто угодно, только не дурак .\n",
            "= he is anything but a fool .\n",
            "< he is anything but a fool . <EOS>\n",
            "\n",
            "> по воскресеньям меня не бывает дома .\n",
            "= i am never at home on sundays .\n",
            "< i am never at home on sundays . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#LSTM +1 рекуррентный слой"
      ],
      "metadata": {
        "id": "sgWWxppJ7j91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder4 = EncoderRNN1(input_lang.n_words, hidden_size, num_rnn=2, rnnClass = \"LSTM\").to(device)\n",
        "decoder4 = DecoderRNN1(hidden_size, output_lang.n_words, num_rnn=2, rnnClass = \"LSTM\").to(device)\n",
        "\n",
        "trainIters(encoder4, decoder4, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVIX6yE61NTQ",
        "outputId": "1dfa6a02-2823-44c8-e2cb-0f510d9e076a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 38s (- 50m 54s) (5000 6%) 3.3987\n",
            "7m 20s (- 47m 44s) (10000 13%) 3.1288\n",
            "11m 4s (- 44m 18s) (15000 20%) 2.8548\n",
            "14m 52s (- 40m 53s) (20000 26%) 2.6272\n",
            "18m 38s (- 37m 17s) (25000 33%) 2.5342\n",
            "22m 26s (- 33m 39s) (30000 40%) 2.4481\n",
            "26m 13s (- 29m 58s) (35000 46%) 2.3344\n",
            "29m 54s (- 26m 9s) (40000 53%) 2.2013\n",
            "33m 37s (- 22m 25s) (45000 60%) 2.1008\n",
            "37m 30s (- 18m 45s) (50000 66%) 1.9850\n",
            "41m 17s (- 15m 0s) (55000 73%) 1.7948\n",
            "45m 10s (- 11m 17s) (60000 80%) 1.6679\n",
            "49m 3s (- 7m 32s) (65000 86%) 1.5526\n",
            "52m 57s (- 3m 46s) (70000 93%) 1.3925\n",
            "56m 52s (- 0m 0s) (75000 100%) 1.3022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder4, decoder4, 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYnobDkw1fvZ",
        "outputId": "12f6e2aa-1ec4-45b5-af09-59f76ba18c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> вы же не очень заняты ?\n",
            "= you aren't very busy, are you ?\n",
            "< you aren't very busy, are you ? <EOS>\n",
            "\n",
            "> ты опоздал .\n",
            "= you are too late .\n",
            "< you are late . <EOS>\n",
            "\n",
            "> они соседи .\n",
            "= they are neighbors .\n",
            "< they are hungry . <EOS>\n",
            "\n",
            "> она так же красива, как и ее мать .\n",
            "= she is as beautiful as her mother .\n",
            "< she is as beautiful as as mother . <EOS>\n",
            "\n",
            "> он слишком осторожен, чтобы попробовать что-либо новое .\n",
            "= he is too cautious to try anything new .\n",
            "< he is too to to go to . . <EOS>\n",
            "\n",
            "> она шьет платье .\n",
            "= she is sewing a dress .\n",
            "< she is wearing a . . <EOS>\n",
            "\n",
            "> нас разделяет только тихии океан .\n",
            "= we are only separated by the pacific ocean .\n",
            "< we are having of time, tom of diseases . <EOS>\n",
            "\n",
            "> они не маленькие дети .\n",
            "= they are not little children .\n",
            "< they aren't not us . <EOS>\n",
            "\n",
            "> она пользуется большои популярностью у мальчиков .\n",
            "= she is very popular among the boys .\n",
            "< she is dressed in white . <EOS>\n",
            "\n",
            "> еи противна ее работа .\n",
            "= she is disgusted with the job .\n",
            "< she is living an unhappy life . <EOS>\n",
            "\n",
            "> он погружен в чтение детективов .\n",
            "= he is absorbed in reading detective novels .\n",
            "< he is absorbed in reading detective novels . <EOS>\n",
            "\n",
            "> я уезжаю на следующеи неделе .\n",
            "= i am leaving next week .\n",
            "< i am leaving next week . <EOS>\n",
            "\n",
            "> она известнее тебя .\n",
            "= she is more famous than you .\n",
            "< she is almost with you . <EOS>\n",
            "\n",
            "> я новыи студент .\n",
            "= i am a new student .\n",
            "< i am a an man . <EOS>\n",
            "\n",
            "> он преподаватель англииского .\n",
            "= he is a teacher of english .\n",
            "< he is a at english teacher . <EOS>\n",
            "\n",
            "> у меня работы по горло .\n",
            "= i am up to my neck in work .\n",
            "< i am up to my neck in work . <EOS>\n",
            "\n",
            "> он всегда полон идеи .\n",
            "= he is always full of ideas .\n",
            "< he is always finding fault . <EOS>\n",
            "\n",
            "> я такая же сильная, как ты .\n",
            "= i am as strong as you .\n",
            "< i am as surprised you you . <EOS>\n",
            "\n",
            "> я уверен, что он не сделал ничего плохого .\n",
            "= i am convinced that he did nothing wrong .\n",
            "< i am not sure when he will come . <EOS>\n",
            "\n",
            "> ему под сорок .\n",
            "= he is about forty .\n",
            "< he is about forty . <EOS>\n",
            "\n",
            "> она ужасно готовит .\n",
            "= she is terrible at cooking .\n",
            "< she is a a . . <EOS>\n",
            "\n",
            "> он завтра уезжает из чикаго .\n",
            "= he is leaving chicago tomorrow .\n",
            "< he is sprawled out of the . . <EOS>\n",
            "\n",
            "> ты не богат .\n",
            "= you aren't rich .\n",
            "< you aren't needed . <EOS>\n",
            "\n",
            "> ты избранныи .\n",
            "= you are the chosen one .\n",
            "< you are the chosen one . <EOS>\n",
            "\n",
            "> тебя тут, по идее, быть не должно .\n",
            "= you aren't supposed to be here .\n",
            "< you aren't supposed to be here . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Значение функции потерь:\n",
        "* GRU 1 рекуррентный слой   loss = 0.0582\n",
        "* GRU 2 рекуррентных слоя   loss = 0.4132\n",
        "* LSTM 1 рекуррентный слой  loss = 0.1181\n",
        "* LSTM 2 рекуррентных слоя  loss = 1.3022\n",
        "\n",
        "2 слоя хуже чем один\n",
        "\n",
        "LSTM с 2 рекуррентными слоями переводит плохо"
      ],
      "metadata": {
        "id": "dRO25DPi83TP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_IpbmX94gvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}