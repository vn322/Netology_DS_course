{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Intro to NN 4 (seminar)",
      "provenance": [],
      "collapsed_sections": [
        "82cwxWvJ_ftF",
        "zlKebc4i_ftH"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMy1y5Ss_fst"
      },
      "source": [
        "# Large scale text analysis with deep learning\n",
        "\n",
        "Today we're gonna apply the newly learned tools for the task of predicting job salary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcwbnkPf_fs2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKLYnj_x_fs3"
      },
      "source": [
        "### About the challenge\n",
        "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0). \n",
        "\n",
        "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blgEXy0a_fs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b12974a-83ac-4895-a460-176ae132a161"
      },
      "source": [
        "!wget https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-29 18:12:44--  https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:601a:18::a27d:712\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/5msc5ix7ndyba10/Train_rev1.csv.tar.gz [following]\n",
            "--2021-03-29 18:12:45--  https://www.dropbox.com/s/raw/5msc5ix7ndyba10/Train_rev1.csv.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc15867f770f4712337848ef972d.dl.dropboxusercontent.com/cd/0/inline/BLlH5dmebGLZsyPD1MYnNi3VHzmzJgGRRvo_3CbM0KBVOkcGwUnLXOIEmjlbhlLzCRc4ljxZNVxyvHi4BmzhoOUzzIEjkmeDP5suL3wEVVRF4HH7semGjU5RwoisLxy2AjnVDVMnB1FmITGXjuRqoQuA/file# [following]\n",
            "--2021-03-29 18:12:45--  https://uc15867f770f4712337848ef972d.dl.dropboxusercontent.com/cd/0/inline/BLlH5dmebGLZsyPD1MYnNi3VHzmzJgGRRvo_3CbM0KBVOkcGwUnLXOIEmjlbhlLzCRc4ljxZNVxyvHi4BmzhoOUzzIEjkmeDP5suL3wEVVRF4HH7semGjU5RwoisLxy2AjnVDVMnB1FmITGXjuRqoQuA/file\n",
            "Resolving uc15867f770f4712337848ef972d.dl.dropboxusercontent.com (uc15867f770f4712337848ef972d.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc15867f770f4712337848ef972d.dl.dropboxusercontent.com (uc15867f770f4712337848ef972d.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BLmbDAWd0uFoBA1EiZDIW9XUSOtZADWrAPyh7TyOOlVSl_7ubtuZa3k4viqICN1MyPKXY_HOHhzNH3qcbmlXqOOLxI3Lj39HyC25ozrtFCjXMCKE2vMILOONyVaPgQwSNXl6jft2XumGk9nCCrpexLR6kLYoNJJzT5tzUZdIwtZbl9QexYeMcSrGgquT7txfqx-W3Q6PfllFTiBHyiYN30ICXRb16_t0atfiRttUO7w6CDP0huIBkYiNI1Y0YUqrWYOO3b9Qd4stIltP7kj8cejQTK5o-bPx4EvsSAUiPwFBInXgAJHCNOQS45ExUKuJ-DLUd86DNR40UJiTHn8_HGhomLFXoM1uoOmdO-iyzptRSAWR2p12o3J7opJkEgc223M/file [following]\n",
            "--2021-03-29 18:12:46--  https://uc15867f770f4712337848ef972d.dl.dropboxusercontent.com/cd/0/inline2/BLmbDAWd0uFoBA1EiZDIW9XUSOtZADWrAPyh7TyOOlVSl_7ubtuZa3k4viqICN1MyPKXY_HOHhzNH3qcbmlXqOOLxI3Lj39HyC25ozrtFCjXMCKE2vMILOONyVaPgQwSNXl6jft2XumGk9nCCrpexLR6kLYoNJJzT5tzUZdIwtZbl9QexYeMcSrGgquT7txfqx-W3Q6PfllFTiBHyiYN30ICXRb16_t0atfiRttUO7w6CDP0huIBkYiNI1Y0YUqrWYOO3b9Qd4stIltP7kj8cejQTK5o-bPx4EvsSAUiPwFBInXgAJHCNOQS45ExUKuJ-DLUd86DNR40UJiTHn8_HGhomLFXoM1uoOmdO-iyzptRSAWR2p12o3J7opJkEgc223M/file\n",
            "Reusing existing connection to uc15867f770f4712337848ef972d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 125441781 (120M) [application/octet-stream]\n",
            "Saving to: ‘Train_rev1.csv.tar.gz’\n",
            "\n",
            "Train_rev1.csv.tar. 100%[===================>] 119.63M   160MB/s    in 0.7s    \n",
            "\n",
            "2021-03-29 18:12:47 (160 MB/s) - ‘Train_rev1.csv.tar.gz’ saved [125441781/125441781]\n",
            "\n",
            "Train_rev1.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244768, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXK8XcTV_fs6"
      },
      "source": [
        "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
        "\n",
        "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
        "\n",
        "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlJq8Du_fs6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c7f668c7-0cc5-4212-8714-7972327d6b50"
      },
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data['Log1pSalary'], bins=20);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIaYg-NO_fs7"
      },
      "source": [
        "Our task is to predict one number, __Log1pSalary__.\n",
        "\n",
        "To do so, our model can access a number of features:\n",
        "* Free text: __`Title`__ and  __`FullDescription`__\n",
        "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOOUvrcm_fs7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "fa4e09c9-62b1-4142-c8d4-ae7dc6046cc0"
      },
      "source": [
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Log1pSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88302</th>\n",
              "      <td>69139346</td>\n",
              "      <td>BDM, Talent Management Software</td>\n",
              "      <td>Do you have excellent analytical skills, with ...</td>\n",
              "      <td>South East England, Berkshire</td>\n",
              "      <td>Berkshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>h2 Recruit Ltd</td>\n",
              "      <td>Other/General Jobs</td>\n",
              "      <td>50,000-74,999 yearly</td>\n",
              "      <td>62499</td>\n",
              "      <td>theladders.co.uk</td>\n",
              "      <td>11.042922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12692</th>\n",
              "      <td>66574321</td>\n",
              "      <td>Travel Consultant</td>\n",
              "      <td>Global travel company, Flight Centre, is seeki...</td>\n",
              "      <td>Oxford</td>\n",
              "      <td>Oxford</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Travel Jobs</td>\n",
              "      <td>25k - 30k</td>\n",
              "      <td>27500</td>\n",
              "      <td>traveljobsearch.com</td>\n",
              "      <td>10.221977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189344</th>\n",
              "      <td>71708841</td>\n",
              "      <td>Alcohol and Drug Collection Technician</td>\n",
              "      <td>An independent specialist provider of integrat...</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "      <td>full_time</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Candidate Source Ltd</td>\n",
              "      <td>Customer Services Jobs</td>\n",
              "      <td>From 10,000 to 10,000 per year</td>\n",
              "      <td>10000</td>\n",
              "      <td>fish4.co.uk</td>\n",
              "      <td>9.210441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Id  ... Log1pSalary\n",
              "88302   69139346  ...   11.042922\n",
              "12692   66574321  ...   10.221977\n",
              "189344  71708841  ...    9.210441\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xp9cDx2_fs8"
      },
      "source": [
        "### Preprocessing text data\n",
        "\n",
        "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
        "\n",
        "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
        "\n",
        "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YCiepvn_fs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a5c80a-55fb-4ec8-9ef3-22349b218a18"
      },
      "source": [
        "print(\"Raw text:\")\n",
        "print(data[\"FullDescription\"][2::100000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw text:\n",
            "2         Mathematical Modeller / Simulation Analyst / O...\n",
            "100002    A successful and high achieving specialist sch...\n",
            "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riDndT8B_fs8"
      },
      "source": [
        "import nltk\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "\n",
        "data[\"FullDescription\"] = data[\"FullDescription\"].astype(str).apply(\n",
        "    lambda x: ' '.join(tokenizer.tokenize(x.lower())), 1)\n",
        "data[\"Title\"] = data[\"Title\"].astype(str).apply(\n",
        "    lambda x: ' '.join(tokenizer.tokenize(x.lower())), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXCAUoLL_fs9"
      },
      "source": [
        "Now we can assume that our text is a space-separated list of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leSlCQ0K_fs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62be807-7bc1-46f2-f670-5022a5a34075"
      },
      "source": [
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9TxF2svM2Tg"
      },
      "source": [
        "huggingface"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtuxOxFh_fs9"
      },
      "source": [
        "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
        "\n",
        "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwoYJjCy_fs-"
      },
      "source": [
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "\n",
        "tokens = []\n",
        "for title in data[\"Title\"]:\n",
        "    tokens += title.split()\n",
        "for title in data[\"FullDescription\"]:\n",
        "    tokens += title.split()\n",
        "    \n",
        "token_counts = Counter(tokens)\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXyIb8Uh_fs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28983c07-6106-482f-a1de-87249a9c7ec3"
      },
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657388)\n",
            "('.', 2523216)\n",
            "(',', 2318606)\n",
            "('the', 2080994)\n",
            "('to', 2019884)\n",
            "...\n",
            "('stephanietraveltraderecruitmnt', 1)\n",
            "('ruabon', 1)\n",
            "('lowehays', 1)\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl6nYPAq_fs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8913a69c-70e1-4f53-bc8f-c105cc6cd583"
      },
      "source": [
        "# Let's see how many words are there for each count\n",
        "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Word counts\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dID9skN_fs_"
      },
      "source": [
        "Now filter tokens a list of all tokens that occur at least 10 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU3jldaQ_fs_"
      },
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7JIpSm_ftA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1df7f29-cf6d-4025-cf91-adce42f9a1fb"
      },
      "source": [
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 34158\n",
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0By6vXx5_ftA"
      },
      "source": [
        "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaW62FAF_ftA"
      },
      "source": [
        "token_to_id = {token: id for id, token in enumerate(tokens)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3gHjAkl_ftB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e150d2a-050b-4d58-e4ae-f0dda4831c16"
      },
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w82YvHL-_ftB"
      },
      "source": [
        "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA9aa63p_ftC"
      },
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykgGjl5XN3By"
      },
      "source": [
        "List[str] -> (batch_size, max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izKzhfa2_ftC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eab9289-18cd-4065-8db2-ba44a98feec8"
      },
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10807 30161  2166     1     1]\n",
            " [15020  2844     1     1     1]\n",
            " [27645 10201    16 15215 10804]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi0Bf6Rf_ftD"
      },
      "source": [
        "Now let's  encode the categirical data we have.\n",
        "\n",
        "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZj8pfKU_ftD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a570a6-6270-47b2-c8c8-290d8e7ac750"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
              "               sparse=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH_24zGX_ftD"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCAafZEh_ftE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef28a590-60bd-4752-ea22-0bb2b14e786b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size =  195814\n",
            "Validation size =  48954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StIHWtEa_ftE"
      },
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PTw54_h_ftE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd43493-e2c4-47bd-8df1-1aa54536c521"
      },
      "source": [
        "make_batch(data_train[:3], max_len=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'FullDescription': array([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451,\n",
              "         32939],\n",
              "        [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,\n",
              "            82],\n",
              "        [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412,\n",
              "         17746]], dtype=int32),\n",
              " 'Log1pSalary': array([ 9.71154 , 10.463132, 10.71444 ], dtype=float32),\n",
              " 'Title': array([[27645, 29893, 33674,     1,     1,     1,     1],\n",
              "        [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
              "        [10609, 30412, 17746,    33,  8705, 29157,    65]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82cwxWvJ_ftF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our basic model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TLINjsi_ftF"
      },
      "source": [
        "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use __[Keras Functional API](https://keras.io/models/model/)__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKV6JqtB_ftG"
      },
      "source": [
        "import keras\n",
        "import keras.layers as L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IRw5ACB_ftG"
      },
      "source": [
        "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
        "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
        "    \n",
        "    l_title = L.Input(shape=[None], name=\"Title\")\n",
        "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
        "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
        "    \n",
        "    # Build your monster!\n",
        "    \n",
        "    emb = L.Embedding(n_tokens, 2 * hid_size)\n",
        "    \n",
        "    l_title_emb = emb(l_title)\n",
        "    l_descr_emb = emb(l_descr)\n",
        "    \n",
        "    l_title_conv = L.Convolution1D(hid_size, kernel_size=2, activation='relu')(l_title_emb)\n",
        "    l_descr_conv = L.Convolution1D(hid_size, kernel_size=5, activation='relu')(l_descr_emb)\n",
        "    \n",
        "    l_title_out = L.GlobalMaxPool1D()(l_title_conv)\n",
        "    l_descr_out = L.GlobalMaxPool1D()(l_descr_conv)\n",
        "    \n",
        "    l_categ_out = L.Dense(hid_size, activation='relu')(l_categ)\n",
        "    \n",
        "    l_combined = L.Concatenate()([l_title_out, l_descr_out, l_categ_out])\n",
        "    l_dense_clf = L.Dense(hid_size, activation='relu')(l_combined)\n",
        "    \n",
        "    output_layer = L.Dense(1)(l_dense_clf)\n",
        "    # end of your code\n",
        "    \n",
        "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
        "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
        "    return model\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7nFNdvl_ftH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0053d3d-deed-4635-e313-1a9c269a68f4"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
        "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
        "assert dummy_pred.shape == (100, 1)\n",
        "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
        "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Title (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "FullDescription (InputLayer)    [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 128)    4372224     Title[0][0]                      \n",
            "                                                                 FullDescription[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, None, 64)     16448       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 64)     41024       embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Categorical (InputLayer)        [(None, 3768)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 64)           0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 64)           0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           241216      Categorical[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 192)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           12352       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            65          dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,683,329\n",
            "Trainable params: 4,683,329\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlKebc4i_ftH"
      },
      "source": [
        "#### Training and evaluation\n",
        "\n",
        "As usual, we gonna feed our monster with random minibatches of data. \n",
        "\n",
        "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wPaV3Z_ftH"
      },
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnwdKJ-C_ftH"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iGUJPt6_ftI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "7650c842-4bc9-4c73-9f81-55504382ab30"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 10            # definitely too small\n",
        "steps_per_epoch = 100  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n",
        "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                    \n",
        "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
        "                    validation_steps=data_val.shape[0] // batch_size\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 55s 542ms/step - loss: 51.9782 - mean_absolute_error: 6.0277 - val_loss: 0.3460 - val_mean_absolute_error: 0.4538\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 41s 406ms/step - loss: 0.2951 - mean_absolute_error: 0.4215 - val_loss: 0.2529 - val_mean_absolute_error: 0.3852\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 39s 393ms/step - loss: 0.1908 - mean_absolute_error: 0.3348 - val_loss: 0.1969 - val_mean_absolute_error: 0.3423\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 35s 357ms/step - loss: 0.1501 - mean_absolute_error: 0.2947 - val_loss: 0.1373 - val_mean_absolute_error: 0.2811\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 33s 324ms/step - loss: 0.1235 - mean_absolute_error: 0.2639 - val_loss: 0.1276 - val_mean_absolute_error: 0.2712\n",
            "Epoch 6/10\n",
            " 37/100 [==========>...................] - ETA: 14s - loss: 0.1079 - mean_absolute_error: 0.2451"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2cd289f91ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                    )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eutHoqk7_ftI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "9a3f1836-4f5f-4791-b937-688629053600"
      },
      "source": [
        "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
        "        batch_pred = model.predict(batch_x)[:, 0]\n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    return squared_error, abs_error\n",
        "    \n",
        "print_metrics(model, data_train, name='Train')\n",
        "print_metrics(model, data_val, name='Val');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-eecee7a39dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msquared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-eecee7a39dbe>\u001b[0m in \u001b[0;36mprint_metrics\u001b[0;34m(model, data, batch_size, name, **kw)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msquared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbatch_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msquared_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mabs_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFD6oVAW_ftI"
      },
      "source": [
        "### Bonus part: explaining model predictions\n",
        "\n",
        "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
        "\n",
        "There are, however, some ways to look inside the black box:\n",
        "* Seeing how model responds to input perturbations\n",
        "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
        "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
        "\n",
        "Today we gonna try the first method just because it's the simplest one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLHwGcR_ftJ"
      },
      "source": [
        "def explain(model, sample, col_name='Title'):\n",
        "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
        "    sample = dict(sample)\n",
        "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
        "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
        "\n",
        "    for drop_i in range(len(sample_col_tokens)):\n",
        "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
        "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
        "\n",
        "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
        "    diffs = baseline_pred - predictions_drop_one_token\n",
        "    return list(zip(sample_col_tokens, diffs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgEHrCqP_ftJ"
      },
      "source": [
        "from IPython.display import HTML, display_html\n",
        "\n",
        "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
        "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
        "              font_style=\"font-size:14px;\"\n",
        "             ):\n",
        "    \n",
        "    def get_color_hex(weight):\n",
        "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
        "        return '#%02X%02X%02X' % rgba[:3]\n",
        "    \n",
        "    tokens_html = [\n",
        "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
        "        for token, weight in tokens_and_weights\n",
        "    ]\n",
        "    \n",
        "    \n",
        "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
        "    if display:\n",
        "        display_html(HTML(raw_html))\n",
        "        \n",
        "    return raw_html\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGQDu_um_ftJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "34ad1ca1-4922-496c-d318-3bd6bebe87fa"
      },
      "source": [
        "i = 36605\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #9E9EFF\">sales</span> <span style=\"background-color: #B0B0FF\">specialist</span> <span style=\"background-color: #FFDEDE\">iv</span> <span style=\"background-color: #FFE6E6\">access</span> <span style=\"background-color: #FCFCFF\">and</span> <span style=\"background-color: #FFE4E4\">infusion</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FEFEFF\">sales</span> <span style=\"background-color: #FEFEFF\">representative</span> <span style=\"background-color: #FEFEFF\">medical</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FEFEFF\">iv</span> <span style=\"background-color: #FEFEFF\">access</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FEFEFF\">infusion</span> <span style=\"background-color: #FFC0C0\">an</span> <span style=\"background-color: #FFF8F8\">opportunity</span> <span style=\"background-color: #FFF8F8\">to</span> <span style=\"background-color: #FF7676\">work</span> <span style=\"background-color: #FEFEFF\">for</span> <span style=\"background-color: #FFECEC\">the</span> <span style=\"background-color: #FFECEC\">industry</span> <span style=\"background-color: #FEFEFF\">leading</span> <span style=\"background-color: #FFECEC\">manufacturer</span> <span style=\"background-color: #FEFEFF\">of</span> <span style=\"background-color: #FFF8F8\">iv</span> <span style=\"background-color: #FFEAEA\">access</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFE8E8\">infusion</span> <span style=\"background-color: #FFF2F2\">solutions</span> <span style=\"background-color: #FFEEEE\">.</span> <span style=\"background-color: #FFF6F6\">formally</span> <span style=\"background-color: #FFB2B2\">recognised</span> <span style=\"background-color: #FFECEC\">as</span> <span style=\"background-color: #FFDADA\">the</span> <span style=\"background-color: #FFE0E0\">number</span> <span style=\"background-color: #FFE6E6\">****</span> <span style=\"background-color: #FEFEFF\">company</span> <span style=\"background-color: #FFD8D8\">in</span> <span style=\"background-color: #FF9C9C\">this</span> <span style=\"background-color: #FFF6F6\">market</span> <span style=\"background-color: #FFCCCC\">space</span> <span style=\"background-color: #FFE8E8\">,</span> <span style=\"background-color: #FFE4E4\">our</span> <span style=\"background-color: #F8F8FF\">client</span> <span style=\"background-color: #FFF6F6\">are</span> <span style=\"background-color: #CECEFF\">an</span> <span style=\"background-color: #FFA6A6\">ethical</span> <span style=\"background-color: #D6D6FF\">and</span> <span style=\"background-color: #FFE2E2\">dynamic</span> <span style=\"background-color: #FFF4F4\">organisation</span> <span style=\"background-color: #FFE2E2\">absolutely</span> <span style=\"background-color: #FFD3D3\">committed</span> <span style=\"background-color: #FFE8E8\">to</span> <span style=\"background-color: #FEFEFF\">the</span> <span style=\"background-color: #FFFAFA\">advancement</span> <span style=\"background-color: #FEFEFF\">of</span> <span style=\"background-color: #FEFEFF\">innovative</span> <span style=\"background-color: #FFE4E4\">technologies</span> <span style=\"background-color: #FEFEFF\">.</span> <span style=\"background-color: #FFCACA\">job</span> <span style=\"background-color: #FFCACA\">title</span> <span style=\"background-color: #FFF0F0\">:</span> <span style=\"background-color: #FEFEFF\">sales</span> <span style=\"background-color: #FEFEFF\">specialist</span> <span style=\"background-color: #FEFEFF\">iv</span> <span style=\"background-color: #FEFEFF\">access</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFF8F8\">infusion</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFF4F4\">:</span> <span style=\"background-color: #FFD6D6\">medication</span> <span style=\"background-color: #FFFCFC\">delivery</span> <span style=\"background-color: #FFF2F2\">solutions</span> <span style=\"background-color: #FFBCBC\">selling</span> <span style=\"background-color: #FF9292\">to</span> <span style=\"background-color: #FFE2E2\">:</span> <span style=\"background-color: #FFD8D8\">iv</span> <span style=\"background-color: #FAFAFF\">teams</span> <span style=\"background-color: #FEFEFF\">,</span> <span style=\"background-color: #FF9696\">infection</span> <span style=\"background-color: #FFF0F0\">control</span> <span style=\"background-color: #FFF0F0\">,</span> <span style=\"background-color: #FFECEC\">lead</span> <span style=\"background-color: #FFDCDC\">intensive</span> <span style=\"background-color: #FFC6C6\">care</span> <span style=\"background-color: #FEFEFF\">nurse</span> <span style=\"background-color: #FFFCFC\">specialists</span> <span style=\"background-color: #FEFEFF\">,</span> <span style=\"background-color: #FFDEDE\">ward</span> <span style=\"background-color: #FFFEFE\">managers</span> <span style=\"background-color: #FFAEAE\">territory</span> <span style=\"background-color: #FFE8E8\">:</span> <span style=\"background-color: #FFEAEA\">east</span> <span style=\"background-color: #FFBABA\">midlands</span> <span style=\"background-color: #FFF2F2\">location</span> <span style=\"background-color: #FFF2F2\">:</span> <span style=\"background-color: #FFFEFE\">east</span> <span style=\"background-color: #FFD3D3\">midlands</span> <span style=\"background-color: #FFB0B0\">package</span> <span style=\"background-color: #FFE8E8\">:</span> <span style=\"background-color: #FF7E7E\">basic</span> <span style=\"background-color: #FFBEBE\">:</span> <span style=\"background-color: #FFC3C3\">****</span> <span style=\"background-color: #FFE6E6\">k</span> <span style=\"background-color: #FFEEEE\">****</span> <span style=\"background-color: #FFE8E8\">k</span> <span style=\"background-color: #FFE0E0\">,</span> <span style=\"background-color: #FFCCCC\">uncapped</span> <span style=\"background-color: #FCFCFF\">bonus</span> <span style=\"background-color: #FFF4F4\">in</span> <span style=\"background-color: #FFA2A2\">addition</span> <span style=\"background-color: #FCFCFF\">,</span> <span style=\"background-color: #FFD2D2\">full</span> <span style=\"background-color: #FFECEC\">corporate</span> <span style=\"background-color: #FFCECE\">benefits</span> <span style=\"background-color: #FFF6F6\">company</span> <span style=\"background-color: #FFFCFC\">information</span> <span style=\"background-color: #FFF4F4\">hugely</span> <span style=\"background-color: #FFC0C0\">ethical</span> <span style=\"background-color: #FFE0E0\">and</span> <span style=\"background-color: #FFDCDC\">professional</span> <span style=\"background-color: #FEFEFF\">global</span> <span style=\"background-color: #FFCCCC\">organisation</span> <span style=\"background-color: #FFECEC\">extremely</span> <span style=\"background-color: #FFE8E8\">well</span> <span style=\"background-color: #FFE8E8\">established</span> <span style=\"background-color: #FFF4F4\">in</span> <span style=\"background-color: #FFB3B3\">the</span> <span style=\"background-color: #FFC3C3\">uk</span> <span style=\"background-color: #FFD2D2\">the</span> <span style=\"background-color: #FFE6E6\">market</span> <span style=\"background-color: #FFE0E0\">leader</span> <span style=\"background-color: #FEFEFF\">across</span> <span style=\"background-color: #FFE0E0\">all</span> <span style=\"background-color: #FFDCDC\">of</span> <span style=\"background-color: #FFCECE\">their</span> <span style=\"background-color: #FFCECE\">core</span> <span style=\"background-color: #FFDCDC\">business</span> <span style=\"background-color: #FFB2B2\">areas</span> <span style=\"background-color: #FFF4F4\">focus</span> <span style=\"background-color: #FFFAFA\">on</span> <span style=\"background-color: #FEFEFF\">providing</span> <span style=\"background-color: #FFE6E6\">cutting</span> <span style=\"background-color: #FFDEDE\">edge</span> <span style=\"background-color: #FEFEFF\">solutions</span> <span style=\"background-color: #FEFEFF\">along</span> <span style=\"background-color: #FEFEFF\">with</span> <span style=\"background-color: #FFEEEE\">outstanding</span> <span style=\"background-color: #FFCECE\">service</span> <span style=\"background-color: #FFE6E6\">and</span> <span style=\"background-color: #FFCCCC\">support</span> <span style=\"background-color: #FEFEFF\">a</span> <span style=\"background-color: #FFE2E2\">business</span> <span style=\"background-color: #FFC6C6\">that</span> <span style=\"background-color: #FFEEEE\">retain</span> <span style=\"background-color: #FFECEC\">talented</span> <span style=\"background-color: #FEFEFF\">personnel</span> <span style=\"background-color: #FFEAEA\">by</span> <span style=\"background-color: #FF9C9C\">offering</span> <span style=\"background-color: #FFBCBC\">a</span> <span style=\"background-color: #FFD8D8\">strong</span> <span style=\"background-color: #FFD3D3\">platform</span> <span style=\"background-color: #FFF0F0\">for</span> <span style=\"background-color: #FFD0D0\">career</span> <span style=\"background-color: #FFFCFC\">development</span> <span style=\"background-color: #FFFCFC\">sales</span> <span style=\"background-color: #FEFEFF\">specialist</span> <span style=\"background-color: #FEFEFF\">iv</span> <span style=\"background-color: #FEFEFF\">access</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFE6E6\">infusion</span> <span style=\"background-color: #FFF4F4\">you</span> <span style=\"background-color: #FEFEFF\">must</span> <span style=\"background-color: #FEFEFF\">have</span> <span style=\"background-color: #FF8383\">/</span> <span style=\"background-color: #FFACAC\">be</span> <span style=\"background-color: #FEFEFF\">the</span> <span style=\"background-color: #F3F3FF\">following</span> <span style=\"background-color: #FFEEEE\">at</span> <span style=\"background-color: #F3F3FF\">least</span> <span style=\"background-color: #FFF6F6\">2</span> <span style=\"background-color: #FFF8F8\">years</span> <span style=\"background-color: #FFBCBC\">medical</span> <span style=\"background-color: #FFB0B0\">device</span> <span style=\"background-color: #FFA0A0\">sales</span> <span style=\"background-color: #FEFEFF\">experience</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #FFD2D2\">candidates</span> <span style=\"background-color: #FFD8D8\">who</span> <span style=\"background-color: #FEFEFF\">have</span> <span style=\"background-color: #FFE4E4\">sold</span> <span style=\"background-color: #FCFCFF\">disposables</span> <span style=\"background-color: #FFF0F0\">/</span> <span style=\"background-color: #FFF4F4\">consumables</span> <span style=\"background-color: #FCFCFF\">or</span> <span style=\"background-color: #FFDCDC\">similar</span> <span style=\"background-color: #FFDEDE\">into</span> <span style=\"background-color: #FFB3B3\">hospitals</span> <span style=\"background-color: #FFFAFA\">would</span> <span style=\"background-color: #FFD3D3\">be</span> <span style=\"background-color: #FFE8E8\">of</span> <span style=\"background-color: #FFD8D8\">particular</span> <span style=\"background-color: #FFA0A0\">interest</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #FFD0D0\">candidates</span> <span style=\"background-color: #FFD0D0\">must</span> <span style=\"background-color: #FFF4F4\">have</span> <span style=\"background-color: #FF8888\">sold</span> <span style=\"background-color: #FFF6F6\">into</span> <span style=\"background-color: #FFDCDC\">hospitals</span> <span style=\"background-color: #FFF8F8\">demonstrable</span> <span style=\"background-color: #FEFEFF\">performance</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFDCDC\">achievements</span> <span style=\"background-color: #FEFEFF\">so</span> <span style=\"background-color: #FEFEFF\">far</span> <span style=\"background-color: #FEFEFF\">personable</span> <span style=\"background-color: #FEFEFF\">,</span> <span style=\"background-color: #FFF4F4\">adaptable</span> <span style=\"background-color: #FFE2E2\">and</span> <span style=\"background-color: #FFF4F4\">willing</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFFCFC\">learn</span> <span style=\"background-color: #FEFEFF\">keen</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FEFEFF\">eager</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFECEC\">be</span> <span style=\"background-color: #FFF8F8\">a</span> <span style=\"background-color: #FFCCCC\">success</span> <span style=\"background-color: #FFBCBC\">candidates</span> <span style=\"background-color: #FFF4F4\">must</span> <span style=\"background-color: #FFBEBE\">have</span> <span style=\"background-color: #FFA8A8\">a</span> <span style=\"background-color: #FFD3D3\">degree</span> <span style=\"background-color: #FFBEBE\">or</span> <span style=\"background-color: #FFF6F6\">at</span> <span style=\"background-color: #FFE6E6\">least</span> <span style=\"background-color: #FEFEFF\">be</span> <span style=\"background-color: #FFF8F8\">able</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFC8C8\">show</span> <span style=\"background-color: #FEFEFF\">a</span> <span style=\"background-color: #FFF2F2\">strong</span> <span style=\"background-color: #FFD2D2\">ability</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFF2F2\">learn</span> <span style=\"background-color: #FEFEFF\">role</span> <span style=\"background-color: #FFDEDE\">information</span> <span style=\"background-color: #FFE2E2\">managing</span> <span style=\"background-color: #FFE2E2\">the</span> <span style=\"background-color: #FFF2F2\">east</span> <span style=\"background-color: #FFFCFC\">midlands</span> <span style=\"background-color: #FFFAFA\">region</span> <span style=\"background-color: #FFF6F6\">selling</span> <span style=\"background-color: #FFE4E4\">across</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFF4F4\">company</span> <span style=\"background-color: #FFDADA\">'</span> <span style=\"background-color: #FFF4F4\">s</span> <span style=\"background-color: #FFFAFA\">range</span> <span style=\"background-color: #FEFEFF\">of</span> <span style=\"background-color: #FFE2E2\">iv</span> <span style=\"background-color: #FFE2E2\">and</span> <span style=\"background-color: #FFE8E8\">infusion</span> <span style=\"background-color: #FEFEFF\">solutions</span> <span style=\"background-color: #FFE4E4\">portfolio</span> <span style=\"background-color: #FFD3D3\">selling</span> <span style=\"background-color: #FFF0F0\">into</span> <span style=\"background-color: #FFFCFC\">lead</span> <span style=\"background-color: #FEFEFF\">intensive</span> <span style=\"background-color: #FFCCCC\">care</span> <span style=\"background-color: #FEFEFF\">nurse</span> <span style=\"background-color: #FFFCFC\">specialists</span> <span style=\"background-color: #FEFEFF\">,</span> <span style=\"background-color: #FFC0C0\">ward</span> <span style=\"background-color: #FFB3B3\">managers</span> <span style=\"background-color: #FFB3B3\">,</span> <span style=\"background-color: #FF8282\">iv</span> <span style=\"background-color: #FFF2F2\">teams</span> <span style=\"background-color: #FFE6E6\">,</span> <span style=\"background-color: #FF7474\">infection</span> <span style=\"background-color: #FFACAC\">control</span> <span style=\"background-color: #FFF4F4\">teams</span> <span style=\"background-color: #FFDEDE\">,</span> <span style=\"background-color: #FFACAC\">procurement</span> <span style=\"background-color: #FFD8D8\">sales</span> <span style=\"background-color: #FEFEFF\">specialist</span> <span style=\"background-color: #FEFEFF\">iv</span> <span style=\"background-color: #FEFEFF\">access</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFEAEA\">infusion</span> <span style=\"background-color: #FFEAEA\">candidates</span> <span style=\"background-color: #DCDCFF\">must</span> <span style=\"background-color: #CACAFF\">be</span> <span style=\"background-color: #FFB0B0\">eligible</span> <span style=\"background-color: #D8D8FF\">to</span> <span style=\"background-color: #F0F0FF\">work</span> <span style=\"background-color: #EAEAFF\">and</span> <span style=\"background-color: #FFA0A0\">live</span> <span style=\"background-color: #FFB0B0\">in</span> <span style=\"background-color: #E0E0FF\">the</span> <span style=\"background-color: #FFAAAA\">uk</span> <span style=\"background-color: #FFCECE\">.</span> <span style=\"background-color: #DEDEFF\">please</span> <span style=\"background-color: #FFEAEA\">contact</span> <span style=\"background-color: #FFBABA\">allan</span> <span style=\"background-color: #FF9A9A\">waller</span> <span style=\"background-color: #FF9292\">on</span> <span style=\"background-color: #FF7070\">****</span> <span style=\"background-color: #FFA2A2\">****</span> <span style=\"background-color: #FF9E9E\">****</span> <span style=\"background-color: #FF9A9A\">or</span> <span style=\"background-color: #FF7474\">please</span> <span style=\"background-color: #FFBABA\">hit</span> <span style=\"background-color: #FEFEFF\">the</span> <span style=\"background-color: #FEFEFF\">apply</span> <span style=\"background-color: #FFFEFE\">button</span> <span style=\"background-color: #FEFEFF\">.</span> <span style=\"background-color: #D2D2FF\">this</span> <span style=\"background-color: #DEDEFF\">job</span> <span style=\"background-color: #FFD3D3\">was</span> <span style=\"background-color: #FFE0E0\">originally</span> <span style=\"background-color: #FFD0D0\">posted</span> <span style=\"background-color: #FFEAEA\">as</span> <span style=\"background-color: #FFC2C2\">www</span> <span style=\"background-color: #F3F3FF\">.</span> <span style=\"background-color: #FFFCFC\">salestarget</span> <span style=\"background-color: #D6D6FF\">.</span> <span style=\"background-color: #FFA6A6\">co</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #D8D8FF\">uk</span> <span style=\"background-color: #FFB6B6\">/</span> <span style=\"background-color: #FFEAEA\">jobseeking</span> <span style=\"background-color: #DEDEFF\">/</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">****</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TbERvwo_ftJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "e54d90ee-1b4e-4457-c2e4-e07bdb14851b"
      },
      "source": [
        "i = 12077\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #FF9696\">cleaning</span> <span style=\"background-color: #FFF4F4\">operative</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FFC8C8\">12</span> <span style=\"background-color: #F2F2FF\">.</span> <span style=\"background-color: #FFC3C3\">5</span> <span style=\"background-color: #FF6C6C\">hours</span> <span style=\"background-color: #FFB3B3\">per</span> <span style=\"background-color: #FF9C9C\">week</span> <span style=\"background-color: #FFE6E6\">monday</span> <span style=\"background-color: #FFD2D2\">friday</span> <span style=\"background-color: #FFB0B0\">9am</span> <span style=\"background-color: #FFD3D3\">11</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #FFA3A3\">30am</span> <span style=\"background-color: #FF7979\">duties</span> <span style=\"background-color: #FFCACA\">to</span> <span style=\"background-color: #FFBEBE\">include</span> <span style=\"background-color: #FFD0D0\">sweeping</span> <span style=\"background-color: #FFDCDC\">,</span> <span style=\"background-color: #FFA2A2\">mopping</span> <span style=\"background-color: #FFD6D6\">,</span> <span style=\"background-color: #FFBCBC\">vacuuming</span> <span style=\"background-color: #FFD8D8\">,</span> <span style=\"background-color: #FF9C9C\">buffing</span> <span style=\"background-color: #FFEEEE\">,</span> <span style=\"background-color: #FFC0C0\">cleaning</span> <span style=\"background-color: #FFAEAE\">staff</span> <span style=\"background-color: #FFC2C2\">toilets</span> <span style=\"background-color: #FAFAFF\">and</span> <span style=\"background-color: #FFAAAA\">rest</span> <span style=\"background-color: #FFB3B3\">room</span> <span style=\"background-color: #FFE8E8\">.</span> <span style=\"background-color: #FFE6E6\">must</span> <span style=\"background-color: #FF9898\">be</span> <span style=\"background-color: #FF8C8C\">able</span> <span style=\"background-color: #FFD8D8\">to</span> <span style=\"background-color: #FFD8D8\">read</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFD0D0\">they</span> <span style=\"background-color: #FFC6C6\">will</span> <span style=\"background-color: #FFC2C2\">be</span> <span style=\"background-color: #FFA8A8\">using</span> <span style=\"background-color: #FEFEFF\">UNK</span> <span style=\"background-color: #FF6060\">which</span> <span style=\"background-color: #FFD8D8\">need</span> <span style=\"background-color: #FEFEFF\">UNK</span> <span style=\"background-color: #FFB0B0\">as</span> <span style=\"background-color: #FFE8E8\">per</span> <span style=\"background-color: #FF6666\">instructions</span> <span style=\"background-color: #FCFCFF\">on</span> <span style=\"background-color: #FFE8E8\">the</span> <span style=\"background-color: #FF8686\">containers</span> <span style=\"background-color: #FFF2F2\">.</span> <span style=\"background-color: #FF8888\">sucessfull</span> <span style=\"background-color: #FFB2B2\">applicants</span> <span style=\"background-color: #FFF4F4\">will</span> <span style=\"background-color: #E0E0FF\">be</span> <span style=\"background-color: #FFB6B6\">trained</span> <span style=\"background-color: #F2F2FF\">on</span> <span style=\"background-color: #FFB2B2\">all</span> <span style=\"background-color: #FFF4F4\">electrical</span> <span style=\"background-color: #FF6969\">appliances</span> <span style=\"background-color: #FFDCDC\">and</span> <span style=\"background-color: #FEFEFF\">UNK</span> <span style=\"background-color: #FFCECE\">of</span> <span style=\"background-color: #FFBCBC\">cleaning</span> <span style=\"background-color: #FFD0D0\">materials</span> <span style=\"background-color: #FCFCFF\">.</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3OAc6fU_ftK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "ec728558-d36c-4933-8539-a073a28f152d"
      },
      "source": [
        "i = np.random.randint(len(data))\n",
        "print(\"Index:\", i)\n",
        "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 11895\n",
            "Salary (gbp): 305.03912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #FFA3A3\">morning</span> <span style=\"background-color: #FF7C7C\">cleaner</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">morning</span> <span style=\"background-color: #FFE6E6\">cleaner</span> <span style=\"background-color: #FFEAEA\">required</span> <span style=\"background-color: #FFFAFA\">for</span> <span style=\"background-color: #FFC3C3\">busy</span> <span style=\"background-color: #FF8E8E\">cinema</span> <span style=\"background-color: #FFE4E4\">in</span> <span style=\"background-color: #FF8080\">redditch</span> <span style=\"background-color: #FFD2D2\">.</span> <span style=\"background-color: #FF9292\">shift</span> <span style=\"background-color: #FFA6A6\">is</span> <span style=\"background-color: #FF5656\">7am</span> <span style=\"background-color: #FFBCBC\">to</span> <span style=\"background-color: #FFA6A6\">9am</span> <span style=\"background-color: #FFAEAE\">6</span> <span style=\"background-color: #FF7878\">days</span> <span style=\"background-color: #FFA3A3\">a</span> <span style=\"background-color: #FF3434\">week</span> <span style=\"background-color: #FFB2B2\">.</span> <span style=\"background-color: #FFD8D8\">duties</span> <span style=\"background-color: #FF7C7C\">are</span> <span style=\"background-color: #FF5151\">daily</span> <span style=\"background-color: #FF7474\">cleaning</span> <span style=\"background-color: #FFDEDE\">and</span> <span style=\"background-color: #FFD3D3\">any</span> <span style=\"background-color: #FF8888\">additional</span> <span style=\"background-color: #FF8888\">work</span> <span style=\"background-color: #FFB6B6\">required</span> <span style=\"background-color: #FF9E9E\">by</span> <span style=\"background-color: #FF7070\">site</span> <span style=\"background-color: #FF2020\">supervisor</span> <span style=\"background-color: #FF8A8A\">.</span> <span style=\"background-color: #FF6E6E\">required</span> <span style=\"background-color: #FF7C7C\">for</span> <span style=\"background-color: #FF8C8C\">3</span> <span style=\"background-color: #FF7878\">months</span> <span style=\"background-color: #FF5050\">sickness</span> <span style=\"background-color: #FF5E5E\">cover</span> <span style=\"background-color: #FF9E9E\">,</span> <span style=\"background-color: #FF8A8A\">the</span> <span style=\"background-color: #FFA2A2\">position</span> <span style=\"background-color: #FF6969\">does</span> <span style=\"background-color: #FFF2F2\">have</span> <span style=\"background-color: #FF8A8A\">the</span> <span style=\"background-color: #FF9393\">potential</span> <span style=\"background-color: #FFDADA\">to</span> <span style=\"background-color: #FF8686\">turn</span> <span style=\"background-color: #FFC6C6\">permenant</span> <span style=\"background-color: #FFB8B8\">if</span> <span style=\"background-color: #FFA6A6\">a</span> <span style=\"background-color: #FFB8B8\">position</span> <span style=\"background-color: #FF4848\">becomes</span> <span style=\"background-color: #FF6C6C\">available</span> <span style=\"background-color: #FF8888\">.</span> <span style=\"background-color: #FF9898\">to</span> <span style=\"background-color: #FF1818\">apply</span> <span style=\"background-color: #FF8686\">please</span> <span style=\"background-color: #FFD6D6\">contact</span> <span style=\"background-color: #FF5151\">lesley</span> <span style=\"background-color: #FFBCBC\">on</span> <span style=\"background-color: #FFF2F2\">****</span></p>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X7CmEkm_ftK"
      },
      "source": [
        "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
      ]
    }
  ]
}